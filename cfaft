import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.metrics import accuracy_score
from transformers import pipeline

class FactReferencer:
    def __init__(self, data):
        self.data = data

    def inside_fact(self, context):
        return [fact for fact in self.data if self._is_relevant(fact, context)]

    def outside_fact(self, external_data):
        return [fact for fact in self.data if self._assess_impact(fact, external_data)]

    def specific_fact(self, scope):
        return [fact for fact in self.data if self._is_specific(fact, scope)]

    def _is_relevant(self, fact, context):
        return fact['context'] == context

    def _assess_impact(self, fact, external_data):
        return fact['external_influence'] in external_data

    def _is_specific(self, fact, scope):
        return fact['scope'] == scope

# Define the AI system
class CriminalActivityIdentifierAI:
    def __init__(self):
        self.data = []
        self.text_data = []
        self.labels = []
        self.features = []
        self.text_features = []
        self.model = None
        self.text_classifier = pipeline("text-classification", model="distilbert-base-uncased-finetuned-sst-2-english")
        self.isolation_forest = IsolationForest(contamination=0.1)
    
    def add_numerical_data(self, features, label):
        """Add numerical data with features and label (1 for truth, 0 for lie)."""
        self.features.append(features)
        self.labels.append(label)
    
    def add_textual_data(self, text, label):
        """Add text data and corresponding label."""
        self.text_data.append(text)
        # Use the language model to generate features from the text
        sentiment_result = self.text_classifier(text)
        sentiment_score = sentiment_result[0]['score']
        sentiment_label = 1 if sentiment_result[0]['label'] == 'POSITIVE' else 0
        self.text_features.append([sentiment_score, sentiment_label])
        self.labels.append(label)
    
    def calculate_energy(self, features):
        """Calculate energy based on input features."""
        return np.sum(features)  # Simplified energy calculation
    
    def train_model(self):
        """Train a machine learning model to classify truth vs lie."""
        # Combine numerical and text features
        combined_features = [np.concatenate([num_feat, text_feat]) for num_feat, text_feat in zip(self.features, self.text_features)]
        
        X_train, X_test, y_train, y_test = train_test_split(combined_features, self.labels, test_size=0.3, random_state=42)
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.model.fit(X_train, y_train)
        predictions = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, predictions)
        print(f"Model Accuracy: {accuracy * 100:.2f}%")

    def predict_truth_lie(self, features, text):
        """Predict whether the given features and text represent truth or lie."""
        sentiment_result = self.text_classifier(text)
        sentiment_score = sentiment_result[0]['score']
        sentiment_label = 1 if sentiment_result[0]['label'] == 'POSITIVE' else 0
        combined_features = np.concatenate([features, [sentiment_score, sentiment_label]])
        prediction = self.model.predict([combined_features])
        return "Truth" if prediction == 1 else "Lie"

    def detect_anomalies(self, features):
        """Detect anomalies using Isolation Forest."""
        anomalies = self.isolation_forest.fit_predict(features)
        anomaly_indices = np.where(anomalies == -1)
        return anomaly_indices

    def simulate_markers(self, truth_features, lie_features):
        """Simulate and visualize the distribution of truth and lie markers."""
        truth_positions = [np.sum(feat) for feat in truth_features]  # Simplified position calculation
        lie_positions = [np.sum(feat) for feat in lie_features]

        plt.figure(figsize=(10, 6))

        plt.scatter(truth_positions, np.zeros_like(truth_positions), c='green', label='Truth Markers', s=100)
        plt.scatter(lie_positions, np.zeros_like(lie_positions), c='red', label='Lie Markers', s=100)

        plt.axhline(0, color='black', linewidth=1)
        plt.title('Truth vs Lie Markers Distribution with AI and ML')
        plt.xlabel('Position')
        plt.yticks([])
        plt.legend()
        plt.grid(True)
        plt.show()

# Example usage
fact_data = [
    {'context': 'local', 'external_influence': 'global', 'scope': 'factory'},
    {'context': 'global', 'external_influence': 'local', 'scope': 'region'},
    # Add more facts as needed
]

fact_referencer = FactReferencer(fact_data)

identifier_ai = CriminalActivityIdentifierAI()

# Example features and text data (e.g., dimensional data, energy calculations, witness statements)
truth_data = [
    ([5.5, 12.0, 0.9], "The suspect was seen leaving the scene at 3 PM."),
    ([6.1, 11.5, 1.2], "Witnesses confirmed that the event occurred at the stated time.")
]
lie_data = [
    ([2.5, 25.0, 0.3], "The suspect claimed to be at home, but no one can verify."),
    ([3.0, 22.0, 0.4], "The story doesn't match the evidence found at the scene.")
]

# Adding data to the system
for features, text in truth_data:
    identifier_ai.add_numerical_data(features, label=1)  # 1 for truth
    identifier_ai.add_textual_data(text, label=1)  # 1 for truth
for features, text in lie_data:
    identifier_ai.add_numerical_data(features, label=0)  # 0 for lie
    identifier_ai.add_textual_data(text, label=0)  # 0 for lie

# Train the model
identifier_ai.train_model()

# Predict on new data
new_features = [5.7, 12.1, 0.95]
new_text = "The suspect was seen near the area but denies being involved."
prediction = identifier_ai.predict_truth_lie(new_features, new_text)
print(f"Prediction for new data: {prediction}")

# Detect anomalies
anomalies = identifier_ai.detect_anomalies(identifier_ai.features)
print(f"Anomalies detected at indices: {anomalies}")

# Simulate and visualize markers
identifier_ai.simulate_markers([f[0] for f in truth_data], [f[0] for f in lie_data])

# Integrating FactReferencer with CriminalActivityIdentifierAI
def integrate_fact_referencer(evidence, fact_referencer):
    relevant_facts = fact_referencer.inside_fact(evidence['context'])
    impact_facts = fact_referencer.outside_fact(evidence['external_data'])
    specific_facts = fact_referencer.specific_fact(evidence['scope'])

    return relevant_facts, impact_facts, specific_facts

# Example evidence
evidence = {
    'context': 'local',
    'external_data': ['global'],
    'scope': 'factory'
}

# Integrate facts
relevant_facts, impact_facts, specific_facts = integrate_fact_referencer(evidence, fact_referencer)
print("Relevant Facts:", relevant_facts)
print("Impact Facts:", impact_facts)
print("Specific Facts:", specific_facts)
